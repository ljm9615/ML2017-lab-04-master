{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 val_loss:  4.55772733416\n",
      "1 2 val_loss:  3.37285823905\n",
      "1 3 val_loss:  2.74860353498\n",
      "1 4 val_loss:  2.37998772279\n",
      "1 5 val_loss:  2.14336137149\n",
      "1 6 val_loss:  1.9813874132\n",
      "1 7 val_loss:  1.86467149014\n",
      "1 8 val_loss:  1.77694093638\n",
      "1 9 val_loss:  1.7086289479\n",
      "1 10 val_loss:  1.65383233557\n",
      "1 11 val_loss:  1.60875923052\n",
      "1 12 val_loss:  1.5708887492\n",
      "1 13 val_loss:  1.53849362281\n",
      "1 14 val_loss:  1.51035798478\n",
      "1 15 val_loss:  1.48560480905\n",
      "1 16 val_loss:  1.46358726697\n",
      "1 17 val_loss:  1.44381853268\n",
      "1 18 val_loss:  1.42592535673\n",
      "1 19 val_loss:  1.40961669429\n",
      "1 20 val_loss:  1.39466208057\n",
      "1 21 val_loss:  1.38087644611\n",
      "1 22 val_loss:  1.36810926768\n",
      "1 23 val_loss:  1.35623668973\n",
      "1 24 val_loss:  1.34515571544\n",
      "1 25 val_loss:  1.33477986229\n",
      "1 26 val_loss:  1.32503586957\n",
      "1 27 val_loss:  1.31586117203\n",
      "1 28 val_loss:  1.30720193895\n",
      "1 29 val_loss:  1.29901153581\n",
      "1 30 val_loss:  1.29124930537\n",
      "1 31 val_loss:  1.28387959288\n",
      "1 32 val_loss:  1.27687095987\n",
      "1 33 val_loss:  1.27019554494\n",
      "1 34 val_loss:  1.2638285401\n",
      "1 35 val_loss:  1.25774775889\n",
      "1 36 val_loss:  1.25193327781\n",
      "1 37 val_loss:  1.24636713675\n",
      "1 38 val_loss:  1.24103308732\n",
      "1 39 val_loss:  1.23591638027\n",
      "1 40 val_loss:  1.23100358495\n",
      "1 41 val_loss:  1.22628243527\n",
      "1 42 val_loss:  1.22174169761\n",
      "1 43 val_loss:  1.21737105717\n",
      "1 44 val_loss:  1.21316101958\n",
      "1 45 val_loss:  1.20910282555\n",
      "1 46 val_loss:  1.20518837646\n",
      "1 47 val_loss:  1.20141016926\n",
      "1 48 val_loss:  1.19776123931\n",
      "1 49 val_loss:  1.19423511002\n",
      "1 50 val_loss:  1.19082574837\n",
      "1 51 val_loss:  1.18752752545\n",
      "1 52 val_loss:  1.18433518133\n",
      "1 53 val_loss:  1.18124379381\n",
      "1 54 val_loss:  1.17824875043\n",
      "1 55 val_loss:  1.17534572331\n",
      "1 56 val_loss:  1.17253064663\n",
      "1 57 val_loss:  1.16979969627\n",
      "1 58 val_loss:  1.16714927143\n",
      "1 59 val_loss:  1.16457597798\n",
      "1 60 val_loss:  1.16207661336\n",
      "1 61 val_loss:  1.15964815284\n",
      "1 62 val_loss:  1.15728773699\n",
      "1 63 val_loss:  1.1549926603\n",
      "1 64 val_loss:  1.15276036064\n",
      "1 65 val_loss:  1.15058840978\n",
      "1 66 val_loss:  1.14847450449\n",
      "1 67 val_loss:  1.14641645856\n",
      "1 68 val_loss:  1.1444121953\n",
      "1 69 val_loss:  1.14245974065\n",
      "1 70 val_loss:  1.14055721691\n",
      "1 71 val_loss:  1.13870283684\n",
      "1 72 val_loss:  1.13689489821\n",
      "1 73 val_loss:  1.13513177882\n",
      "1 74 val_loss:  1.13341193176\n",
      "1 75 val_loss:  1.13173388114\n",
      "1 76 val_loss:  1.13009621799\n",
      "1 77 val_loss:  1.12849759655\n",
      "1 78 val_loss:  1.1269367307\n",
      "1 79 val_loss:  1.12541239075\n",
      "1 80 val_loss:  1.12392340032\n",
      "1 81 val_loss:  1.12246863354\n",
      "1 82 val_loss:  1.12104701232\n",
      "1 83 val_loss:  1.11965750387\n",
      "1 84 val_loss:  1.11829911836\n",
      "1 85 val_loss:  1.11697090669\n",
      "1 86 val_loss:  1.11567195843\n",
      "1 87 val_loss:  1.11440139987\n",
      "1 88 val_loss:  1.11315839222\n",
      "1 89 val_loss:  1.11194212983\n",
      "1 90 val_loss:  1.11075183864\n",
      "1 91 val_loss:  1.10958677461\n",
      "1 92 val_loss:  1.10844622226\n",
      "1 93 val_loss:  1.10732949339\n",
      "1 94 val_loss:  1.10623592573\n",
      "1 95 val_loss:  1.10516488174\n",
      "1 96 val_loss:  1.1041157475\n",
      "1 97 val_loss:  1.1030879316\n",
      "1 98 val_loss:  1.10208086413\n",
      "1 99 val_loss:  1.10109399569\n",
      "1 100 val_loss:  1.10012679651\n",
      "2 1 val_loss:  4.43559936936\n",
      "2 2 val_loss:  3.19802020699\n",
      "2 3 val_loss:  2.56139668263\n",
      "2 4 val_loss:  2.19780922298\n",
      "2 5 val_loss:  1.97205732531\n",
      "2 6 val_loss:  1.82182250243\n",
      "2 7 val_loss:  1.71585099633\n",
      "2 8 val_loss:  1.63736739184\n",
      "2 9 val_loss:  1.57683840269\n",
      "2 10 val_loss:  1.52857091286\n",
      "2 11 val_loss:  1.48901198327\n",
      "2 12 val_loss:  1.45585457903\n",
      "2 13 val_loss:  1.427545829\n",
      "2 14 val_loss:  1.40300585991\n",
      "2 15 val_loss:  1.3814612926\n",
      "2 16 val_loss:  1.36234343065\n",
      "2 17 val_loss:  1.34522413376\n",
      "2 18 val_loss:  1.32977429436\n",
      "2 19 val_loss:  1.31573624348\n",
      "2 20 val_loss:  1.30290496132\n",
      "2 21 val_loss:  1.2911149884\n",
      "2 22 val_loss:  1.28023111217\n",
      "2 23 val_loss:  1.27014160909\n",
      "2 24 val_loss:  1.26075325169\n",
      "2 25 val_loss:  1.25198755857\n",
      "2 26 val_loss:  1.24377793559\n",
      "2 27 val_loss:  1.23606746689\n",
      "2 28 val_loss:  1.228807187\n",
      "2 29 val_loss:  1.22195471441\n",
      "2 30 val_loss:  1.21547316018\n",
      "2 31 val_loss:  1.2093302483\n",
      "2 32 val_loss:  1.2034976011\n",
      "2 33 val_loss:  1.19795015407\n",
      "2 34 val_loss:  1.19266567376\n",
      "2 35 val_loss:  1.18762435778\n",
      "2 36 val_loss:  1.18280850118\n",
      "2 37 val_loss:  1.17820221662\n",
      "2 38 val_loss:  1.17379119846\n",
      "2 39 val_loss:  1.16956252294\n",
      "2 40 val_loss:  1.16550447822\n",
      "2 41 val_loss:  1.16160641914\n",
      "2 42 val_loss:  1.15785864267\n",
      "2 43 val_loss:  1.15425228059\n",
      "2 44 val_loss:  1.15077920686\n",
      "2 45 val_loss:  1.14743195721\n",
      "2 46 val_loss:  1.14420365918\n",
      "2 47 val_loss:  1.14108797113\n",
      "2 48 val_loss:  1.13807902872\n",
      "2 49 val_loss:  1.13517139804\n",
      "2 50 val_loss:  1.13236003423\n",
      "2 51 val_loss:  1.12964024499\n",
      "2 52 val_loss:  1.12700765826\n",
      "2 53 val_loss:  1.12445819351\n",
      "2 54 val_loss:  1.12198803619\n",
      "2 55 val_loss:  1.119593615\n",
      "2 56 val_loss:  1.1172715814\n",
      "2 57 val_loss:  1.11501879144\n",
      "2 58 val_loss:  1.1128322893\n",
      "2 59 val_loss:  1.11070929251\n",
      "2 60 val_loss:  1.10864717861\n",
      "2 61 val_loss:  1.1066434731\n",
      "2 62 val_loss:  1.10469583854\n",
      "2 63 val_loss:  1.10280206456\n",
      "2 64 val_loss:  1.10096005893\n",
      "2 65 val_loss:  1.09916783925\n",
      "2 66 val_loss:  1.09742352553\n",
      "2 67 val_loss:  1.09572533327\n",
      "2 68 val_loss:  1.09407156719\n",
      "2 69 val_loss:  1.09246061549\n",
      "2 70 val_loss:  1.09089094452\n",
      "2 71 val_loss:  1.0893610939\n",
      "2 72 val_loss:  1.08786967203\n",
      "2 73 val_loss:  1.08641535198\n",
      "2 74 val_loss:  1.08499686757\n",
      "2 75 val_loss:  1.08361300988\n",
      "2 76 val_loss:  1.08226262395\n",
      "2 77 val_loss:  1.0809446057\n",
      "2 78 val_loss:  1.07965789909\n",
      "2 79 val_loss:  1.0784014935\n",
      "2 80 val_loss:  1.07717442123\n",
      "2 81 val_loss:  1.07597575526\n",
      "2 82 val_loss:  1.07480460702\n",
      "2 83 val_loss:  1.07366012447\n",
      "2 84 val_loss:  1.07254149017\n",
      "2 85 val_loss:  1.07144791953\n",
      "2 86 val_loss:  1.07037865919\n",
      "2 87 val_loss:  1.06933298543\n",
      "2 88 val_loss:  1.06831020275\n",
      "2 89 val_loss:  1.06730964251\n",
      "2 90 val_loss:  1.06633066161\n",
      "2 91 val_loss:  1.06537264129\n",
      "2 92 val_loss:  1.06443498603\n",
      "2 93 val_loss:  1.06351712242\n",
      "2 94 val_loss:  1.06261849818\n",
      "2 95 val_loss:  1.06173858119\n",
      "2 96 val_loss:  1.06087685856\n",
      "2 97 val_loss:  1.06003283585\n",
      "2 98 val_loss:  1.05920603614\n",
      "2 99 val_loss:  1.05839599938\n",
      "2 100 val_loss:  1.05760228158\n",
      "3 1 val_loss:  4.48653916206\n",
      "3 2 val_loss:  3.25472017086\n",
      "3 3 val_loss:  2.62191105876\n",
      "3 4 val_loss:  2.25659806501\n",
      "3 5 val_loss:  2.02587977988\n",
      "3 6 val_loss:  1.86943125333\n",
      "3 7 val_loss:  1.75711233521\n",
      "3 8 val_loss:  1.67266231013\n",
      "3 9 val_loss:  1.60673753126\n",
      "3 10 val_loss:  1.55367678438\n",
      "3 11 val_loss:  1.50989042916\n",
      "3 12 val_loss:  1.47301029178\n",
      "3 13 val_loss:  1.4414184355\n",
      "3 14 val_loss:  1.41397465005\n",
      "3 15 val_loss:  1.38985289735\n",
      "3 16 val_loss:  1.36843984847\n",
      "3 17 val_loss:  1.34927003246\n",
      "3 18 val_loss:  1.33198324367\n",
      "3 19 val_loss:  1.31629586289\n",
      "3 20 val_loss:  1.3019811002\n",
      "3 21 val_loss:  1.28885509489\n",
      "3 22 val_loss:  1.27676694509\n",
      "3 23 val_loss:  1.26559142787\n",
      "3 24 val_loss:  1.25522359625\n",
      "3 25 val_loss:  1.24557470856\n",
      "3 26 val_loss:  1.23656911893\n",
      "3 27 val_loss:  1.22814187177\n",
      "3 28 val_loss:  1.22023681885\n",
      "3 29 val_loss:  1.21280512959\n",
      "3 30 val_loss:  1.2058041006\n",
      "3 31 val_loss:  1.19919619561\n",
      "3 32 val_loss:  1.19294826456\n",
      "3 33 val_loss:  1.18703090343\n",
      "3 34 val_loss:  1.18141792552\n",
      "3 35 val_loss:  1.17608592183\n",
      "3 36 val_loss:  1.17101389315\n",
      "3 37 val_loss:  1.16618294043\n",
      "3 38 val_loss:  1.16157600262\n",
      "3 39 val_loss:  1.15717763363\n",
      "3 40 val_loss:  1.15297381166\n",
      "3 41 val_loss:  1.14895177538\n",
      "3 42 val_loss:  1.14509988265\n",
      "3 43 val_loss:  1.14140748818\n",
      "3 44 val_loss:  1.13786483707\n",
      "3 45 val_loss:  1.13446297208\n",
      "3 46 val_loss:  1.13119365228\n",
      "3 47 val_loss:  1.12804928171\n",
      "3 48 val_loss:  1.1250228465\n",
      "3 49 val_loss:  1.12210785925\n",
      "3 50 val_loss:  1.11929830988\n",
      "3 51 val_loss:  1.11658862179\n",
      "3 52 val_loss:  1.11397361302\n",
      "3 53 val_loss:  1.11144846138\n",
      "3 54 val_loss:  1.10900867339\n",
      "3 55 val_loss:  1.10665005633\n",
      "3 56 val_loss:  1.10436869323\n",
      "3 57 val_loss:  1.10216092022\n",
      "3 58 val_loss:  1.10002330618\n",
      "3 59 val_loss:  1.09795263433\n",
      "3 60 val_loss:  1.09594588556\n",
      "3 61 val_loss:  1.09400022327\n",
      "3 62 val_loss:  1.09211297965\n",
      "3 63 val_loss:  1.09028164315\n",
      "3 64 val_loss:  1.08850384708\n",
      "3 65 val_loss:  1.08677735921\n",
      "3 66 val_loss:  1.08510007223\n",
      "3 67 val_loss:  1.08346999506\n",
      "3 68 val_loss:  1.08188524481\n",
      "3 69 val_loss:  1.08034403953\n",
      "3 70 val_loss:  1.07884469139\n",
      "3 71 val_loss:  1.0773856005\n",
      "3 72 val_loss:  1.07596524922\n",
      "3 73 val_loss:  1.07458219685\n",
      "3 74 val_loss:  1.07323507478\n",
      "3 75 val_loss:  1.071922582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 76 val_loss:  1.07064348091\n",
      "3 77 val_loss:  1.06939659345\n",
      "3 78 val_loss:  1.06818079758\n",
      "3 79 val_loss:  1.06699502387\n",
      "3 80 val_loss:  1.06583825251\n",
      "3 81 val_loss:  1.06470951035\n",
      "3 82 val_loss:  1.0636078683\n",
      "3 83 val_loss:  1.06253243877\n",
      "3 84 val_loss:  1.06148237342\n",
      "3 85 val_loss:  1.06045686094\n",
      "3 86 val_loss:  1.05945512506\n",
      "3 87 val_loss:  1.05847642263\n",
      "3 88 val_loss:  1.05752004188\n",
      "3 89 val_loss:  1.05658530074\n",
      "3 90 val_loss:  1.0556715453\n",
      "3 91 val_loss:  1.05477814835\n",
      "3 92 val_loss:  1.05390450803\n",
      "3 93 val_loss:  1.05305004652\n",
      "3 94 val_loss:  1.05221420886\n",
      "3 95 val_loss:  1.05139646181\n",
      "3 96 val_loss:  1.05059629281\n",
      "3 97 val_loss:  1.04981320891\n",
      "3 98 val_loss:  1.04904673591\n",
      "3 99 val_loss:  1.04829641741\n",
      "3 100 val_loss:  1.047561814\n",
      "4 1 val_loss:  4.51480921854\n",
      "4 2 val_loss:  3.3532887437\n",
      "4 3 val_loss:  2.72984215385\n",
      "4 4 val_loss:  2.35515105548\n",
      "4 5 val_loss:  2.11035863016\n",
      "4 6 val_loss:  1.93989437631\n",
      "4 7 val_loss:  1.81511361548\n",
      "4 8 val_loss:  1.72007456834\n",
      "4 9 val_loss:  1.64533644687\n",
      "4 10 val_loss:  1.58501228477\n",
      "4 11 val_loss:  1.53526719034\n",
      "4 12 val_loss:  1.49350753978\n",
      "4 13 val_loss:  1.45792126898\n",
      "4 14 val_loss:  1.4272060173\n",
      "4 15 val_loss:  1.40040232378\n",
      "4 16 val_loss:  1.37678787763\n",
      "4 17 val_loss:  1.35580848005\n",
      "4 18 val_loss:  1.33703176241\n",
      "4 19 val_loss:  1.32011540488\n",
      "4 20 val_loss:  1.30478482971\n",
      "4 21 val_loss:  1.29081723004\n",
      "4 22 val_loss:  1.27802992628\n",
      "4 23 val_loss:  1.26627173676\n",
      "4 24 val_loss:  1.25541648661\n",
      "4 25 val_loss:  1.24535805858\n",
      "4 26 val_loss:  1.23600657316\n",
      "4 27 val_loss:  1.22728540746\n",
      "4 28 val_loss:  1.21912884517\n",
      "4 29 val_loss:  1.2114802068\n",
      "4 30 val_loss:  1.20429034972\n",
      "4 31 val_loss:  1.19751645544\n",
      "4 32 val_loss:  1.19112104225\n",
      "4 33 val_loss:  1.18507115599\n",
      "4 34 val_loss:  1.17933770285\n",
      "4 35 val_loss:  1.17389489607\n",
      "4 36 val_loss:  1.16871979472\n",
      "4 37 val_loss:  1.16379191724\n",
      "4 38 val_loss:  1.15909291607\n",
      "4 39 val_loss:  1.15460630261\n",
      "4 40 val_loss:  1.15031721355\n",
      "4 41 val_loss:  1.14621221164\n",
      "4 42 val_loss:  1.14227911519\n",
      "4 43 val_loss:  1.13850685146\n",
      "4 44 val_loss:  1.13488533035\n",
      "4 45 val_loss:  1.13140533496\n",
      "4 46 val_loss:  1.12805842669\n",
      "4 47 val_loss:  1.12483686252\n",
      "4 48 val_loss:  1.1217335227\n",
      "4 49 val_loss:  1.11874184746\n",
      "4 50 val_loss:  1.11585578128\n",
      "4 51 val_loss:  1.1130697239\n",
      "4 52 val_loss:  1.11037848688\n",
      "4 53 val_loss:  1.10777725524\n",
      "4 54 val_loss:  1.10526155328\n",
      "4 55 val_loss:  1.10282721424\n",
      "4 56 val_loss:  1.10047035312\n",
      "4 57 val_loss:  1.09818734246\n",
      "4 58 val_loss:  1.09597479056\n",
      "4 59 val_loss:  1.09382952195\n",
      "4 60 val_loss:  1.09174855981\n",
      "4 61 val_loss:  1.08972911005\n",
      "4 62 val_loss:  1.08776854702\n",
      "4 63 val_loss:  1.08586440052\n",
      "4 64 val_loss:  1.08401434399\n",
      "4 65 val_loss:  1.08221618384\n",
      "4 66 val_loss:  1.08046784972\n",
      "4 67 val_loss:  1.07876738561\n",
      "4 68 val_loss:  1.07711294177\n",
      "4 69 val_loss:  1.07550276727\n",
      "4 70 val_loss:  1.07393520326\n",
      "4 71 val_loss:  1.07240867675\n",
      "4 72 val_loss:  1.07092169485\n",
      "4 73 val_loss:  1.0694728396\n",
      "4 74 val_loss:  1.06806076307\n",
      "4 75 val_loss:  1.06668418294\n",
      "4 76 val_loss:  1.0653418784\n",
      "4 77 val_loss:  1.06403268632\n",
      "4 78 val_loss:  1.0627554978\n",
      "4 79 val_loss:  1.06150925484\n",
      "4 80 val_loss:  1.0602929474\n",
      "4 81 val_loss:  1.05910561055\n",
      "4 82 val_loss:  1.05794632193\n",
      "4 83 val_loss:  1.05681419928\n",
      "4 84 val_loss:  1.05570839822\n",
      "4 85 val_loss:  1.05462811017\n",
      "4 86 val_loss:  1.05357256036\n",
      "4 87 val_loss:  1.05254100606\n",
      "4 88 val_loss:  1.05153273484\n",
      "4 89 val_loss:  1.05054706298\n",
      "4 90 val_loss:  1.04958333402\n",
      "4 91 val_loss:  1.04864091731\n",
      "4 92 val_loss:  1.04771920677\n",
      "4 93 val_loss:  1.04681761961\n",
      "4 94 val_loss:  1.04593559518\n",
      "4 95 val_loss:  1.04507259395\n",
      "4 96 val_loss:  1.04422809644\n",
      "4 97 val_loss:  1.04340160226\n",
      "4 98 val_loss:  1.04259262926\n",
      "4 99 val_loss:  1.04180071263\n",
      "4 100 val_loss:  1.04102540414\n",
      "5 1 val_loss:  4.43703321655\n",
      "5 2 val_loss:  3.34487517302\n",
      "5 3 val_loss:  2.75096879304\n",
      "5 4 val_loss:  2.3902292368\n",
      "5 5 val_loss:  2.15252929156\n",
      "5 6 val_loss:  1.98586998537\n",
      "5 7 val_loss:  1.86319975733\n",
      "5 8 val_loss:  1.76933533345\n",
      "5 9 val_loss:  1.69521728448\n",
      "5 10 val_loss:  1.63516032995\n",
      "5 11 val_loss:  1.58544195979\n",
      "5 12 val_loss:  1.54353493674\n",
      "5 13 val_loss:  1.50766911582\n",
      "5 14 val_loss:  1.47657059516\n",
      "5 15 val_loss:  1.44930066099\n",
      "5 16 val_loss:  1.42515309015\n",
      "5 17 val_loss:  1.40358675625\n",
      "5 18 val_loss:  1.38418025065\n",
      "5 19 val_loss:  1.36660061174\n",
      "5 20 val_loss:  1.3505813227\n",
      "5 21 val_loss:  1.33590653694\n",
      "5 22 val_loss:  1.32239957474\n",
      "5 23 val_loss:  1.30991440477\n",
      "5 24 val_loss:  1.29832924735\n",
      "5 25 val_loss:  1.28754170974\n",
      "5 26 val_loss:  1.27746504332\n",
      "5 27 val_loss:  1.26802523337\n",
      "5 28 val_loss:  1.25915871385\n",
      "5 29 val_loss:  1.25081055688\n",
      "5 30 val_loss:  1.24293302615\n",
      "5 31 val_loss:  1.23548441203\n",
      "5 32 val_loss:  1.2284280868\n",
      "5 33 val_loss:  1.22173173303\n",
      "5 34 val_loss:  1.21536670927\n",
      "5 35 val_loss:  1.20930752564\n",
      "5 36 val_loss:  1.20353140747\n",
      "5 37 val_loss:  1.1980179305\n",
      "5 38 val_loss:  1.19274871411\n",
      "5 39 val_loss:  1.18770716217\n",
      "5 40 val_loss:  1.18287824306\n",
      "5 41 val_loss:  1.17824830207\n",
      "5 42 val_loss:  1.17380490071\n",
      "5 43 val_loss:  1.16953667854\n",
      "5 44 val_loss:  1.16543323386\n",
      "5 45 val_loss:  1.16148502034\n",
      "5 46 val_loss:  1.157683257\n",
      "5 47 val_loss:  1.15401984972\n",
      "5 48 val_loss:  1.15048732244\n",
      "5 49 val_loss:  1.14707875673\n",
      "5 50 val_loss:  1.14378773847\n",
      "5 51 val_loss:  1.14060831082\n",
      "5 52 val_loss:  1.13753493235\n",
      "5 53 val_loss:  1.13456244002\n",
      "5 54 val_loss:  1.13168601598\n",
      "5 55 val_loss:  1.12890115806\n",
      "5 56 val_loss:  1.12620365326\n",
      "5 57 val_loss:  1.12358955393\n",
      "5 58 val_loss:  1.12105515639\n",
      "5 59 val_loss:  1.11859698161\n",
      "5 60 val_loss:  1.11621175777\n",
      "5 61 val_loss:  1.11389640446\n",
      "5 62 val_loss:  1.11164801833\n",
      "5 63 val_loss:  1.1094638601\n",
      "5 64 val_loss:  1.10734134267\n",
      "5 65 val_loss:  1.10527802033\n",
      "5 66 val_loss:  1.10327157887\n",
      "5 67 val_loss:  1.10131982654\n",
      "5 68 val_loss:  1.09942068577\n",
      "5 69 val_loss:  1.09757218558\n",
      "5 70 val_loss:  1.09577245458\n",
      "5 71 val_loss:  1.09401971457\n",
      "5 72 val_loss:  1.09231227461\n",
      "5 73 val_loss:  1.09064852554\n",
      "5 74 val_loss:  1.08902693498\n",
      "5 75 val_loss:  1.08744604261\n",
      "5 76 val_loss:  1.08590445589\n",
      "5 77 val_loss:  1.08440084607\n",
      "5 78 val_loss:  1.08293394441\n",
      "5 79 val_loss:  1.0815025388\n",
      "5 80 val_loss:  1.08010547053\n",
      "5 81 val_loss:  1.07874163127\n",
      "5 82 val_loss:  1.07740996033\n",
      "5 83 val_loss:  1.07610944206\n",
      "5 84 val_loss:  1.07483910341\n",
      "5 85 val_loss:  1.07359801167\n",
      "5 86 val_loss:  1.07238527238\n",
      "5 87 val_loss:  1.0712000273\n",
      "5 88 val_loss:  1.07004145261\n",
      "5 89 val_loss:  1.06890875713\n",
      "5 90 val_loss:  1.06780118072\n",
      "5 91 val_loss:  1.06671799272\n",
      "5 92 val_loss:  1.06565849051\n",
      "5 93 val_loss:  1.0646219982\n",
      "5 94 val_loss:  1.0636078653\n",
      "5 95 val_loss:  1.06261546556\n",
      "5 96 val_loss:  1.0616441958\n",
      "5 97 val_loss:  1.06069347489\n",
      "5 98 val_loss:  1.05976274271\n",
      "5 99 val_loss:  1.05885145921\n",
      "5 100 val_loss:  1.05795910353\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ0EppVSahoJSSqk0DQWllFJp/x9r62JDR2n9rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d13a6815c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    读取数据\n",
    "    :param path: 文件路径\n",
    "    :return: 数据矩阵(943 * 1682)\n",
    "    \"\"\"\n",
    "    ratings = [[0 for column in range(1682)] for row in range(943)]\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        id, movie, rating = line.split('\\t')[:3]\n",
    "        ratings[int(id) - 1][int(movie) - 1] = float(rating)\n",
    "    return np.array(ratings)\n",
    "\n",
    "\n",
    "def matrix_factorize(data, k):\n",
    "    \"\"\"\n",
    "    初始化用户因子矩阵和物品（电影）因子矩阵\n",
    "    :param data: 训练集\n",
    "    :param k: 潜在特征数\n",
    "    :return: 用户因子矩阵和物品（电影）因子矩阵\n",
    "    \"\"\"\n",
    "    user_num = len(data)\n",
    "    item_num = len(data[0])\n",
    "    P = np.random.rand(user_num, k)\n",
    "    Q = np.random.rand(item_num, k)\n",
    "    return P, Q.T\n",
    "\n",
    "\n",
    "def get_loss_update(Y, Y_pre, P, Q, K, learning_rate, Lambda):\n",
    "    \"\"\"\n",
    "    更新参数\n",
    "    :param Y: 训练集结果\n",
    "    :param P: 用户因子矩阵\n",
    "    :param Q: 物品（电影）因子矩阵\n",
    "    :param K: 潜在特征数\n",
    "    :param learning_rate: 学习率\n",
    "    :param Lambda: 正则化系数\n",
    "    :return: 更新后的用户因子矩阵，物品（电影）因子矩阵，和预测结果矩阵\n",
    "    \"\"\"\n",
    "\n",
    "    counter = 0\n",
    "    for row in range(len(Y)):\n",
    "        for column in range(len(Y[row])):\n",
    "            if Y[row][column] > 0:\n",
    "                counter += 1\n",
    "                eij = Y[row][column] - np.dot(P[row, :], Q[:, column])\n",
    "                for k in range(K):\n",
    "                    P[row][k] = P[row][k] + learning_rate * (2 * eij * Q[k][column] - Lambda * P[row][k])\n",
    "                    Q[k][column] = Q[k][column] + learning_rate * (2 * eij * P[row][k] - Lambda * Q[k][column])\n",
    "    return P, Q, np.dot(P, Q)\n",
    "\n",
    "\n",
    "def get_val_loss(Y, Y_pre, P, Q):\n",
    "    \"\"\"\n",
    "    获得在测试集上的loss\n",
    "    :param Y: 测试集结果矩阵\n",
    "    :param Y_pre: 预测结果矩阵\n",
    "    :param P: 用户因子矩阵\n",
    "    :param Q: 物品（电影）因子矩阵\n",
    "    :return: 测试集上的loss\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    counter = 0\n",
    "    for row in range(len(Y)):\n",
    "        for column in range(len(Y[row])):\n",
    "            if Y[row][column] > 0:\n",
    "                counter += 1\n",
    "                loss += (Y[row][column] - Y_pre[row][column]) * (Y[row][column] - Y_pre[row][column])\n",
    "                for k in range(K):\n",
    "                    loss += Lambda / 2 * (pow(P[row][k], 2) + pow(Q[k][column], 2))\n",
    "    return loss / counter\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 初始化参数\n",
    "    learning_rate = 0.0001\n",
    "    Lambda = 0.01\n",
    "    K = 20\n",
    "    epoch = 100\n",
    "    all_losses = []\n",
    "    all_val_losses = []\n",
    "\n",
    "    # 针对不同的训练集和测试集\n",
    "    for counter in range(5):\n",
    "        # losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        # 读取数据\n",
    "        train_data = read_data(r\"E:\\machine learning\\lab4\\ml-100k\\ml-100k\\u\" + str(counter + 1) + \".base\")\n",
    "        test_data = read_data(r\"E:\\machine learning\\lab4\\ml-100k\\ml-100k\\u\" + str(counter + 1) + \".test\")\n",
    "\n",
    "        # 初始化用户因子矩阵和物品（电影）因子矩阵\n",
    "        P_user_k, Q_item_k = matrix_factorize(train_data, K)\n",
    "        val_data = np.dot(P_user_k, Q_item_k)\n",
    "\n",
    "        # 更新参数，获得loss\n",
    "        for i in range(epoch):\n",
    "\n",
    "            # 计算在测试集上的loss\n",
    "            val_loss = get_val_loss(test_data, val_data, P_user_k, Q_item_k)\n",
    "            val_losses.append(val_loss)\n",
    "            print(counter + 1, i + 1, \"val_loss: \", val_loss)\n",
    "\n",
    "            # 更新参数\n",
    "            P_user_k, Q_item_k, val_data = get_loss_update(train_data, val_data, P_user_k, Q_item_k,\n",
    "                                                           K, learning_rate, Lambda)\n",
    "\n",
    "        all_val_losses.append(val_losses)\n",
    "\n",
    "    # loss随迭代次数的变化图\n",
    "    # plt.plot(range(epoch * 2), losses, label=\"loss\", color='red')\n",
    "    plt.plot(range(epoch), all_val_losses[0], label=\"u1\", color='green')\n",
    "    plt.plot(range(epoch), all_val_losses[1], label=\"u2\", color='red')\n",
    "    plt.plot(range(epoch), all_val_losses[2], label=\"u3\", color='blue')\n",
    "    plt.plot(range(epoch), all_val_losses[3], label=\"u4\", color='yellow')\n",
    "    plt.plot(range(epoch), all_val_losses[4], label=\"u5\", color='black')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
